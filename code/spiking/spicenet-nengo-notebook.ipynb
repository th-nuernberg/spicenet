{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.random import uniform, randn\n",
    "import nengo"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametrisierung der Lernrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "def parametrize_learning_law(v0, vf, t0, tf, learning_type):\n",
    "    assert learning_type in ('sigmoid', 'invtime', 'exp')\n",
    "\n",
    "    #Matrix zur Speicherung der parametrisierten Lernrate für jeden Schritt\n",
    "    y = np.zeros((tf - t0,))\n",
    "\n",
    "    #Zeitschritte von 1 bis tf\n",
    "    t = np.array([i for i in range(1, tf +1 )])\n",
    "\n",
    "    #Unterscheidung nach Lernarten (sigmoid, invtime, exp)\n",
    "    if learning_type == 'sigmoid':\n",
    "        s = -np.floor(np.log10(tf)) * 10**(-(np.floor(np.log10(tf))))\n",
    "        p = abs(s*10**(np.floor(np.log10(tf)) + np.floor(np.log10(tf))/2))\n",
    "        y = v0 - (v0)/(1+np.exp(s*(t-(tf/p)))) + vf\n",
    "    \n",
    "    elif learning_type == 'invtime':\n",
    "        B = (vf * tf - v0 * t0) / (v0 - vf)\n",
    "        A = v0 * t0 + B * v0\n",
    "        y = [A / (t[i] + B) for i in range(len(t))]\n",
    "    \n",
    "    elif learning_type == 'exp':\n",
    "        if v0 < 1:\n",
    "            p = -np.log(v0)\n",
    "        else:\n",
    "            p = np.log(v0)\n",
    "        y = v0 * np.exp(-t/(tf/p))\n",
    "\n",
    "    return y"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "#Anzahl Ensembles\n",
    "N_ENS = 2\n",
    "\n",
    "#Anzahl der Neuronen in SOM\n",
    "N_NEURONS = 50\n",
    "\n",
    "#Wertebereich\n",
    "RADIUS = 1.\n",
    "\n",
    "#Schrittweite der Nengo-Simulation\n",
    "DT = .001\n",
    "\n",
    "#Max Anzahl Epochen für inneres Lernen der SOM\n",
    "MAX_EPOCHS_IN_LEARNING = 50\n",
    "\n",
    "#Max Anzahl Epochen für äußeres Lernen der SOM\n",
    "MAX_EPOCHS_XMOD_LEARNING = 100\n",
    "\n",
    "#Anzahl Samples für Training\n",
    "N_SAMPLES = 1500\n",
    "\n",
    "#Aktivitätsverfallrate\n",
    "ETA = 1.\n",
    "\n",
    "#Gewichtsverfallrate\n",
    "XI = 1e-3\n",
    "\n",
    "#Lernarten\n",
    "LEARNING_TYPES = ['sigmoid', 'invtime', 'exp']\n",
    "\n",
    "#Parametrisierung der Lernraten\n",
    "sigma0 = N_NEURONS / 2. #ursprünglicher Wert\n",
    "sigmaf = 1.             #finaler Wert\n",
    "SIGMAT = parametrize_learning_law(v0=sigma0, vf=sigmaf, t0=1, tf=MAX_EPOCHS_IN_LEARNING, learning_type='invtime')\n",
    "alpha0 = .1             #ursprünglicher Wert\n",
    "alphaf = .001           #finaler Wert\n",
    "ALPHAT = parametrize_learning_law(v0=alpha0, vf=alphaf, t0=1, tf=MAX_EPOCHS_IN_LEARNING, learning_type='exp')\n",
    "\n",
    "#Vorhandene Sensoren\n",
    "SENSORES = ['x', 'y']\n",
    "assert len(SENSORES) == N_ENS\n",
    "\n",
    "ACTIVITY = {}\n",
    "for i in range(N_ENS):\n",
    "    ACTIVITY[i] = np.zeros((N_NEURONS))\n",
    "\n",
    "# Matrizen für Inputgewichte zwischen den Neuronen werden abgespeichert, um als transform-Parameter auf Ensembles angewandt werden zu können\n",
    "INPUT_WEIGHTS = {}\n",
    "for i, _ in enumerate(SENSORES):\n",
    "    INPUT_WEIGHTS[i] = np.zeros((N_NEURONS,))\n",
    "\n",
    "# Standartabweichungen zur Berechnungen der Gewichtsänderungen\n",
    "SIGMA_DEF =.045\n",
    "STD = {}\n",
    "for i, _ in enumerate(SENSORES):\n",
    "    STD[i] = SIGMA_DEF * np.ones((N_NEURONS,))\n",
    "\n",
    "# Matrizen für X-Korrelation zwischen den Neuronen werden abgespeichert, um als transform-Parameter auf Ensembles angewandt werden zu können\n",
    "W_CROSS = uniform(0, 1, (N_NEURONS, N_NEURONS))\n",
    "XMOD_WEIGHTS = {}\n",
    "for i, _ in enumerate(SENSORES):\n",
    "    XMOD_WEIGHTS[i] = W_CROSS / W_CROSS.sum()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "source": [
    "#setzt Parameter zurück zur Wiederverwendung\n",
    "def reset_matrices():\n",
    "    for i, _ in enumerate(SENSORES):\n",
    "        ACTIVITY[i] = np.zeros((N_NEURONS,))\n",
    "        INPUT_WEIGHTS[i] = np.zeros((N_NEURONS,))\n",
    "        STD[i] = SIGMA_DEF * np.ones((N_NEURONS,))\n",
    "        XMOD_WEIGHTS[i] = W_CROSS / W_CROSS.sum()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(ALPHAT, linewidth=3)\n",
    "plt.xlabel('Epochen')\n",
    "plt.ylabel('Hebbian Learning rate')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(SIGMAT, linewidth=3)\n",
    "plt.xlabel('Epochen')\n",
    "plt.ylabel('SOM neighborhood size')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensordaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "def generate_test_data():\n",
    "    data = {}\n",
    "\n",
    "    x_std = .25\n",
    "    data['x'] = np.array(np.random.uniform(-1,1, N_SAMPLES))\n",
    "    \n",
    "    y_std = .025\n",
    "    data['y'] = np.array([x**3 + randn() * y_std for _,x in enumerate(data['x'])])\n",
    "\n",
    "    return data"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "data = generate_test_data()\n",
    "sensory_data = np.column_stack((data['x'], data['y']))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "plt.plot(data['y'], data['x'], '.')\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.hist(data['x'],bins=50,facecolor=\"blue\", edgecolor=\"black\", alpha=0.7)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.hist(data['y'],bins=50,facecolor=\"blue\", edgecolor=\"black\", alpha=0.7)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lernalgorithmen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update-Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "source": [
    "#für Ansatz, welcher nur den activity-Vektor als Ensemble implementiert\n",
    "def update_activity_vector(sensor, activity, datapoint):\n",
    "    #Initialisierung des Aktivitätsvektors auf 0\n",
    "    act_cur = np.zeros((N_NEURONS,))\n",
    "\n",
    "    #Berechnen der Aktivität des Neurons auf Basis von Sensorinput und aktueller Gewichtung\n",
    "    act_cur = (1 / (np.sqrt(2 * np.pi) * STD[sensor])) * np.exp(-np.square(datapoint - INPUT_WEIGHTS[sensor]) / (2 * np.square(STD[sensor])))\n",
    "\n",
    "    #Normalisierung des Aktivitätsvektors der Population\n",
    "    if act_cur.sum() != 0:\n",
    "        act_cur /= act_cur.sum()\n",
    "    \n",
    "    #Aktualisierung der Aktivität für die nächste Iteration\n",
    "    activity = (1 - ETA) * activity + ETA * act_cur\n",
    "    \n",
    "    return activity"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "#für Ansatz, welcher winput, activity und std je als Ensemble implementiert\n",
    "def update_activity_vector1(winput, activity, std, datapoint):\n",
    "    #Initialisierung des Aktivitätsvektors auf 0\n",
    "    act_cur = np.zeros((N_NEURONS,))\n",
    "\n",
    "    #hier kann teilen durch 0 auftreten, weshalb 0-Werte ersetzt werden\n",
    "    std = np.maximum(std, 1e-4)\n",
    "    act_cur = (1 / (np.sqrt(2 * np.pi) * std)) * np.exp(-np.square(datapoint - winput) / (2 * np.square(std)))\n",
    "\n",
    "    #Normalisierung des Aktivitätsvektors der Population\n",
    "    if act_cur.sum() != 0:\n",
    "        act_cur /= act_cur.sum()\n",
    "    \n",
    "    #Aktualisierung der Aktivität für die nächste Iteration\n",
    "    activity = (1 - ETA) * activity + ETA * act_cur\n",
    "    return activity"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inneres Lernen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "source": [
    "#für Ansatz, welcher nur den activity-Vektor als Ensemble implementiert\n",
    "def inner_learning(activities, epoch):\n",
    "    #Kernelwert (Differenz zw. Pos. des aktuellen Neurons und der Pos. des Neurons mit der höchsten Aktivität)\n",
    "    hwi = np.zeros((N_NEURONS,))\n",
    "\n",
    "    #Werte der Lernraten bleiben bei Schleifendurchläufe konstant und müssen so nur einmal gelesen werden\n",
    "    alpha = ALPHAT[epoch-1]\n",
    "    sigma = SIGMAT[epoch-1]\n",
    "\n",
    "    #Faktor ändert sich nicht in Schleifendurchläufen und muss nur einmal berechnet werden\n",
    "    factor = 1 / (np.sqrt(2 * np.pi) * sigma)\n",
    "\n",
    "    for _, datapoint in enumerate(sensory_data): #iterieren über Datenpunkte\n",
    "        for i in range(len(SENSORES)):\n",
    "            # update the activity for the next iteration\n",
    "            activities[i] = update_activity_vector(i, activities[i], datapoint[i])\n",
    "\n",
    "            #Bestimmung des Neurons mit höchster Aktivität (Gewinnerneuron)\n",
    "            win_pos = np.argmax(activities[i])\n",
    "\n",
    "            #Berechnung des Kernelwerts für Neuronen\n",
    "            #einfacher Gauß'scher Kernel ohne Berücksichtigung der Begrenzungen\n",
    "            hwi = np.exp(-np.square(np.arange(N_NEURONS) - win_pos) / (2 * sigma**2))\n",
    "\n",
    "            #Aktualisierung der Gewichtungen der Neuronen\n",
    "            INPUT_WEIGHTS[i] += alpha * hwi * (datapoint[i] - INPUT_WEIGHTS[i])\n",
    "\n",
    "            #Aktualisierungen der std der Neuronen\n",
    "            STD[i] += alpha * factor * hwi * (np.square(datapoint[i] - INPUT_WEIGHTS[i]) - np.square(STD[i]))\n",
    "    return activities"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "#für Ansatz, welcher winput, activity und std je als Ensemble implementiert\n",
    "def inner_learning1(winputs, activities, stds, epoch):\n",
    "    #Kernelwert (Differenz zw. Pos. des aktuellen Neurons und der Pos. des Neurons mit der höchsten Aktivität)\n",
    "    hwi = np.zeros((N_NEURONS,))\n",
    "\n",
    "    #Werte der Lernraten bleiben bei Schleifendurchläufe konstant und müssen so nur einmal gelesen werden\n",
    "    alpha = ALPHAT[epoch-1]\n",
    "    sigma = SIGMAT[epoch-1]\n",
    "\n",
    "    #Faktor ändert sich nicht in Schleifendurchläufen und muss nur einmal berechnet werden\n",
    "    factor = 1 / (np.sqrt(2 * np.pi) * sigma)\n",
    "\n",
    "    for _, datapoint in enumerate(sensory_data): #iterieren über Datenpunkte\n",
    "        for i in range(len(SENSORES)):\n",
    "            # update the activity for the next iteration\n",
    "            activities[i] = update_activity_vector1(winputs[i], activities[i], stds[i], datapoint[i])\n",
    "\n",
    "            #Bestimmung des Neurons mit höchster Aktivität (Gewinnerneuron)\n",
    "            win_pos = np.argmax(activities[i])\n",
    "\n",
    "            #Berechnung des Kernelwerts für Neuronen\n",
    "            #einfacher Gauß'scher Kernel ohne Berücksichtigung der Begrenzungen\n",
    "            hwi = np.exp(-np.square(np.arange(N_NEURONS) - win_pos) / (2 * sigma**2))\n",
    "\n",
    "            #Aktualisierung der Gewichtungen der Neuronen\n",
    "            winputs[i] += alpha * hwi * (datapoint[i] - winputs[i])\n",
    "\n",
    "            #Aktualisierungen der std der Neuronen\n",
    "            stds[i] += alpha * factor * hwi * ((datapoint[i] - winputs[i])**2 - stds[i]**2)\n",
    "    return (winputs, activities, stds)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XMod-Lernen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hebbian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "source": [
    "#für Ansatz, welcher nur den activity-Vektor als Ensemble implementiert\n",
    "def hebbian_learning(activities):\n",
    "    for _, datapoint in enumerate(sensory_data):\n",
    "        #Aktualisierung des Aktivitätsvektor\n",
    "        for i in range(N_ENS):\n",
    "            activities[i] = update_activity_vector(i, activities[i], datapoint[i])\n",
    "\n",
    "        #Hebb'sche Regel für Kreuzmodalität: Multiplikation der Aktivitäten\n",
    "        XMOD_WEIGHTS[0] = (1 - XI) * XMOD_WEIGHTS[0] + XI * activities[0] * activities[1].T\n",
    "        XMOD_WEIGHTS[1] = (1 - XI) * XMOD_WEIGHTS[1] + XI * activities[1] * activities[0].T \n",
    "    \n",
    "    return activities"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "#für Ansatz, welcher winput, activity und std je als Ensemble implementiert\n",
    "def hebbian_learning1(winputs, activities, stds): #, xmod_weights):\n",
    "    for _, datapoint in enumerate(sensory_data):\n",
    "        #Aktualisierung des Aktivitätsvektor\n",
    "        for i in range(N_ENS):\n",
    "            activities[i] = update_activity_vector1(winputs[i], activities[i], stds[i], datapoint[i])\n",
    "\n",
    "        #Hebb'sche Regel für Kreuzmodalität: Multiplikation der Aktivitäten\n",
    "        XMOD_WEIGHTS[0] = (1 - XI) * XMOD_WEIGHTS[0] + XI * activities[0] * activities[1].T\n",
    "        #xmod_weights = (1 - XI) * xmod_weights + XI * activities[0] * activities[1].T\n",
    "        XMOD_WEIGHTS[1] = (1 - XI) * XMOD_WEIGHTS[1] + XI * activities[1] * activities[0].T\n",
    "    \n",
    "    return activities"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "source": [
    "#für Ansatz, welcher nur den activity-Vektor als Ensemble implementiert\n",
    "def covariance_learning(activities, epoch):\n",
    "    #  mean activities for covariance learning\n",
    "    avg_act = np.zeros((N_NEURONS, N_ENS))\n",
    "\n",
    "    # Berechnung des Abfalls für den Mittelwert\n",
    "    omega = .002 + .998 / (epoch + 2)\n",
    "\n",
    "    for _, datapoint in enumerate(sensory_data):\n",
    "        for i in range(N_ENS):\n",
    "            #Aktualisierung des Aktivitätsvektor\n",
    "            activities[i] = update_activity_vector(i, activities[i], datapoint[i])\n",
    "            # Berechnung des Abfalls für den Mittelwert\n",
    "            avg_act[:, i] = (1 - omega) * avg_act[:, i] + omega * activities[i][:]\n",
    "\n",
    "        #Kreuzmodale Hebb'sche Kovarianz-Lernregel: Aktualisierung der Gewichte basierenf auf Kovarianz\n",
    "        XMOD_WEIGHTS[0] = (1 - XI) * XMOD_WEIGHTS[0] + XI * (activities[0] - \\\n",
    "                          avg_act[:, 0].reshape(N_NEURONS,1)) * (activities[1] - avg_act[:,1].reshape(N_NEURONS,1)).T\n",
    "        XMOD_WEIGHTS[1] = (1 - XI) * XMOD_WEIGHTS[1] + XI * (activities[1] - \\\n",
    "                          avg_act[:, 1].reshape(N_NEURONS,1)) * (activities[0] - avg_act[:, 0].reshape(N_NEURONS,1)).T\n",
    "\n",
    "    return activities"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "#für Ansatz, welcher winput, activity und std je als Ensemble implementiert\n",
    "def covariance_learning1(winputs, activities, stds, epoch):\n",
    "    #  mean activities for covariance learning\n",
    "    avg_act = np.zeros((N_NEURONS, N_ENS))\n",
    "\n",
    "    # Berechnung des Abfalls für den Mittelwert\n",
    "    omega = .002 + .998 / (epoch + 2)\n",
    "\n",
    "    for _, datapoint in enumerate(sensory_data):\n",
    "        for i in range(N_ENS):\n",
    "            #Aktualisierung des Aktivitätsvektor\n",
    "            activities[i] = update_activity_vector1(winputs[i], activities[i], stds[i], datapoint[i])\n",
    "            # Berechnung des Abfalls für den Mittelwert\n",
    "            avg_act[:, i] = (1 - omega) * avg_act[:, i] + omega * activities[i][:]\n",
    "\n",
    "        #Kreuzmodale Hebb'sche Kovarianz-Lernregel: Aktualisierung der Gewichte basierenf auf Kovarianz\n",
    "        XMOD_WEIGHTS[0] = (1 - XI) * XMOD_WEIGHTS[0] + XI * (activities[0] - \\\n",
    "                          avg_act[:, 0].reshape(N_NEURONS,1)) * (activities[1] - avg_act[:,1].reshape(N_NEURONS,1)).T\n",
    "        #xmod_weights = (1 - XI) * xmod_weights + XI * (activities[0] - \\\n",
    "        #               avg_act[:, 0].reshape(N_NEURONS,1)) * (activities[1] - avg_act[:,1].reshape(N_NEURONS,1)).T\n",
    "        XMOD_WEIGHTS[1] = (1 - XI) * XMOD_WEIGHTS[1] + XI * (activities[1] - \\\n",
    "                          avg_act[:, 1].reshape(N_NEURONS,1)) * (activities[0] - avg_act[:, 0].reshape(N_NEURONS,1)).T\n",
    "        \n",
    "    return activities"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "source": [
    "#für Ansatz, welcher nur den activity-Vektor als Ensemble implementiert\n",
    "def oja_learning(activities):\n",
    "    for _, datapoint in enumerate(sensory_data):\n",
    "        #Aktualisierung des Aktivitätsvektor\n",
    "        for i in range(N_ENS):\n",
    "            activities[i] = update_activity_vector(i, activities[i], datapoint[i])\n",
    "\n",
    "        # Oja'sche lokale PCA-Lernregel\n",
    "        XMOD_WEIGHTS[0] = ((1 - XI) * XMOD_WEIGHTS[0] + XI * activities[0] * activities[1].T) / \\\n",
    "                          np.sqrt(sum(sum((1 - XI) * XMOD_WEIGHTS[0] + XI * activities[0] * activities[1].T)))\n",
    "        XMOD_WEIGHTS[1] = ((1 - XI) * XMOD_WEIGHTS[1] + XI * activities[1] * activities[0].T) / \\\n",
    "                          np.sqrt(sum(sum((1 - XI) * XMOD_WEIGHTS[1] + XI * activities[1] * activities[0].T)))\n",
    "\n",
    "    return activities"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "#für Ansatz, welcher winput, activity und std je als Ensemble implementiert\n",
    "def oja_learning1(winputs, activities, stds): #, xmod_weights):\n",
    "    for _, datapoint in enumerate(sensory_data):\n",
    "        #Aktualisierung des Aktivitätsvektor\n",
    "        for i in range(N_ENS):\n",
    "            activities[i] = update_activity_vector1(winputs[i], activities[i], stds[i], datapoint[i])\n",
    "\n",
    "        # Oja'sche lokale PCA-Lernregel\n",
    "        XMOD_WEIGHTS[0] = ((1 - XI) * XMOD_WEIGHTS[0] + XI * activities[0] * activities[1].T) / \\\n",
    "                          np.sqrt(sum(sum((1 - XI) * XMOD_WEIGHTS[0] + XI * activities[0] * activities[1].T)))\n",
    "        #xmod_weights = ((1 - XI) * xmod_weights + XI * activities[0] * activities[1].T) / \\\n",
    "        #               np.sqrt(sum(sum((1 - XI) * xmod_weights + XI * activities[0] * activities[1].T)))\n",
    "        XMOD_WEIGHTS[1] = ((1 - XI) * XMOD_WEIGHTS[1] + XI * activities[1] * activities[0].T) / \\\n",
    "                          np.sqrt(sum(sum((1 - XI) * XMOD_WEIGHTS[1] + XI * activities[1] * activities[0].T)))\n",
    "        \n",
    "    return activities"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ansatz 1: Nengo-Implementierung von Winput-, Aktivitäts- und std-Vektor der SOMs je als Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nur Inner-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "reset_matrices()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class InnerLearnProcess(nengo.Process):\n",
    "    def make_step(self, shape_in, shape_out, dt, rng, state=None):\n",
    "        def step(t, x):\n",
    "            epoch = int(t/DT)\n",
    "\n",
    "            if epoch == 0: #wenn erster Durchlauf, Werte der Neuronen initialisieren\n",
    "                winputs = np.zeros((N_ENS, N_NEURONS))\n",
    "                activities = np.zeros((N_ENS, N_NEURONS))\n",
    "                stds = np.ones((N_ENS, N_NEURONS)) * SIGMA_DEF\n",
    "                #xmod_weights = W_CROSS / W_CROSS.sum()\n",
    "            else:\n",
    "                winputs = np.array([x[:N_NEURONS], x[N_NEURONS:N_NEURONS*2]])\n",
    "                activities = np.array([x[N_NEURONS*2:N_NEURONS*3], x[N_NEURONS*3:N_NEURONS*4]])\n",
    "                stds = np.array([x[N_NEURONS*4:N_NEURONS*5], x[N_NEURONS*5:N_NEURONS*6]])\n",
    "                #xmod_weights = np.array(x[N_NEURONS*6:]).reshape((N_NEURONS, N_NEURONS))\n",
    "            \n",
    "            #Inneres Lernen\n",
    "            if epoch <= MAX_EPOCHS_IN_LEARNING:\n",
    "                (winputs, activities, stds) = inner_learning1(winputs, activities, stds, epoch)\n",
    "\n",
    "            return np.concatenate((winputs.flatten(), activities.flatten(), stds.flatten()), axis=None)\n",
    "        return step"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "with nengo.Network() as net_inner:\n",
    "    #Repräsentation der WInput-Vektoren als Ensembles\n",
    "    winput_x = nengo.networks.EnsembleArray(N_NEURONS*50, n_ensembles=N_NEURONS, radius=RADIUS)\n",
    "    winput_y = nengo.networks.EnsembleArray(N_NEURONS*50, n_ensembles=N_NEURONS, radius=RADIUS)\n",
    "\n",
    "    #Repräsentation der Aktivitäts-Vektoren als Ensembles\n",
    "    activity_x = nengo.networks.EnsembleArray(N_NEURONS*50, n_ensembles=N_NEURONS, radius=RADIUS)\n",
    "    activity_y = nengo.networks.EnsembleArray(N_NEURONS*50, n_ensembles=N_NEURONS, radius=RADIUS)\n",
    "\n",
    "    #Repräsentation der std-Vektoren als Ensembles\n",
    "    std_x = nengo.networks.EnsembleArray(N_NEURONS*50, n_ensembles=N_NEURONS, radius=RADIUS)\n",
    "    std_y = nengo.networks.EnsembleArray(N_NEURONS*50, n_ensembles=N_NEURONS, radius=RADIUS)\n",
    "\n",
    "    #xmod_weights = nengo.networks.EnsembleArray(N_NEURONS*N_NEURONS*30, n_ensembles=N_NEURONS*N_NEURONS, radius=RADIUS)\n",
    "\n",
    "    learn_node = nengo.Node(InnerLearnProcess(), size_in=N_NEURONS*N_ENS*3, size_out=N_NEURONS*N_ENS*3)\n",
    "\n",
    "    #Verbindungen von Neuronen der Ensembles zur Lernmethode ...\n",
    "    nengo.Connection(winput_x.output, learn_node[:N_NEURONS])\n",
    "    nengo.Connection(winput_y.output, learn_node[N_NEURONS:N_NEURONS*2])\n",
    "    nengo.Connection(activity_x.output, learn_node[N_NEURONS*2:N_NEURONS*3])\n",
    "    nengo.Connection(activity_y.output, learn_node[N_NEURONS*3:N_NEURONS*4])\n",
    "    nengo.Connection(std_x.output, learn_node[N_NEURONS*4:N_NEURONS*5])\n",
    "    nengo.Connection(std_y.output, learn_node[N_NEURONS*5:N_NEURONS*6])\n",
    "    #nengo.Connection(xmod_weights.output, learn_node[N_NEURONS*6:])\n",
    "    # ... und wieder zurück\n",
    "    nengo.Connection(learn_node[:N_NEURONS], winput_x.input)\n",
    "    nengo.Connection(learn_node[N_NEURONS:N_NEURONS*2], winput_y.input)\n",
    "    nengo.Connection(learn_node[N_NEURONS*2:N_NEURONS*3], activity_x.input)\n",
    "    nengo.Connection(learn_node[N_NEURONS*3:N_NEURONS*4], activity_y.input)\n",
    "    nengo.Connection(learn_node[N_NEURONS*4:N_NEURONS*5], std_x.input)\n",
    "    nengo.Connection(learn_node[N_NEURONS*5:N_NEURONS*6], std_y.input)\n",
    "    #nengo.Connection(learn_node[N_NEURONS*6:], xmod_weights.input)\n",
    "\n",
    "    #Proben\n",
    "    p_inner_winput_x = nengo.Probe(winput_x)\n",
    "    p_inner_winput_y = nengo.Probe(winput_y)\n",
    "    p_inner_activity_x = nengo.Probe(activity_x)\n",
    "    p_inner_activity_y = nengo.Probe(activity_y)\n",
    "    p_inner_std_x = nengo.Probe(std_x)\n",
    "    p_inner_std_y = nengo.Probe(std_y)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "with nengo.Simulator(net_inner) as s_inner:\n",
    "    s_inner.run_steps(MAX_EPOCHS_IN_LEARNING)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisierung activity-Vektoren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.bar(range(N_NEURONS), s_inner.data[p_inner_activity_x][-1])\n",
    "plt.title('activity_x')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Wert')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.bar(range(N_NEURONS), s_inner.data[p_inner_activity_y][-1])\n",
    "plt.title('activity_y')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Wert')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisierung winput-Vektoren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.bar(range(N_NEURONS), s_inner.data[p_inner_winput_x][-1])\n",
    "plt.title('winput_x')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Wert')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.bar(range(N_NEURONS), s_inner.data[p_inner_winput_y][-1])\n",
    "plt.title('winput_y')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Wert')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.grid()\n",
    "x = np.linspace(-RADIUS, RADIUS, N_NEURONS)\n",
    "for i in range(N_NEURONS):\n",
    "    # extract the preferred values (wight vector) of each neuron\n",
    "    v_pref = s_inner.data[p_inner_winput_x][-1][i]\n",
    "    fx = np.exp(-(x - v_pref)**2 / (2 * s_inner.data[p_inner_std_x][-1][i]**2))\n",
    "    plt.plot([x for x in range(N_NEURONS)], fx)\n",
    "    \n",
    "plt.subplot(2, 1, 2)\n",
    "plt.grid()\n",
    "x = np.linspace(-RADIUS, RADIUS, N_NEURONS)\n",
    "for i in range(N_NEURONS):\n",
    "    # extract the preferred values (wight vector) of each neuron\n",
    "    v_pref = s_inner.data[p_inner_winput_y][-1][i]\n",
    "    fx = np.exp(-(x - v_pref)**2 / (2 * s_inner.data[p_inner_std_y][-1][i]**2))\n",
    "    plt.plot([x for x in range(N_NEURONS)], fx)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisierung std-Vektoren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.bar(range(N_NEURONS), s_inner.data[p_inner_std_x][-1])\n",
    "plt.title('std_x')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Wert')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.bar(range(N_NEURONS), s_inner.data[p_inner_std_y][-1])\n",
    "plt.title('std_y')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Wert')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nur XMod-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class XModLearnProcess(nengo.Process):\n",
    "    def make_step(self, shape_in, shape_out, dt, rng, state=None):\n",
    "        def step(t, x):\n",
    "            epoch = int(t/DT)\n",
    "\n",
    "            if epoch == 0: #wenn erster Durchlauf, Werte der Neuronen initialisieren\n",
    "                winputs = np.zeros((N_ENS, N_NEURONS))\n",
    "                activities = np.zeros((N_ENS, N_NEURONS))\n",
    "                stds = np.ones((N_ENS, N_NEURONS)) * SIGMA_DEF\n",
    "                #xmod_weights = W_CROSS / W_CROSS.sum()\n",
    "            else:\n",
    "                winputs = np.array([x[:N_NEURONS], x[N_NEURONS:N_NEURONS*2]])\n",
    "                activities = np.array([x[N_NEURONS*2:N_NEURONS*3], x[N_NEURONS*3:N_NEURONS*4]])\n",
    "                stds = np.array([x[N_NEURONS*4:N_NEURONS*5], x[N_NEURONS*5:N_NEURONS*6]])\n",
    "                #xmod_weights = np.array(x[N_NEURONS*6:]).reshape((N_NEURONS, N_NEURONS))\n",
    "\n",
    "            #XMOD-Lernen\n",
    "            activities = \\\n",
    "            covariance_learning1(winputs, activities, stds, epoch)\n",
    "            #oja_learning1(winputs, activities, stds)\n",
    "            #hebbian_learning1(winputs, activities, stds)\n",
    "\n",
    "            return np.concatenate((winputs.flatten(), activities.flatten(), stds.flatten()), axis=None)\n",
    "        return step"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "with nengo.Network() as net_xmod:\n",
    "    #Repräsentation der WInput-Vektoren als Ensembles\n",
    "    winput_x = nengo.networks.EnsembleArray(N_NEURONS*50, n_ensembles=N_NEURONS, radius=RADIUS)\n",
    "    winput_y = nengo.networks.EnsembleArray(N_NEURONS*50, n_ensembles=N_NEURONS, radius=RADIUS)\n",
    "\n",
    "    #Repräsentation der Aktivitäts-Vektoren als Ensembles\n",
    "    activity_x = nengo.networks.EnsembleArray(N_NEURONS*50, n_ensembles=N_NEURONS, radius=RADIUS)\n",
    "    activity_y = nengo.networks.EnsembleArray(N_NEURONS*50, n_ensembles=N_NEURONS, radius=RADIUS)\n",
    "\n",
    "    #Repräsentation der std-Vektoren als Ensembles\n",
    "    std_x = nengo.networks.EnsembleArray(N_NEURONS*50, n_ensembles=N_NEURONS, radius=RADIUS)\n",
    "    std_y = nengo.networks.EnsembleArray(N_NEURONS*50, n_ensembles=N_NEURONS, radius=RADIUS)\n",
    "\n",
    "    #xmod_weights = nengo.networks.EnsembleArray(N_NEURONS*N_NEURONS*30, n_ensembles=N_NEURONS*N_NEURONS, radius=RADIUS)\n",
    "\n",
    "    learn_node = nengo.Node(XModLearnProcess(), size_in=N_NEURONS*N_ENS*3, size_out=N_NEURONS*N_ENS*3)\n",
    "\n",
    "    #Verbindungen von Neuronen der Ensembles zur Lernmethode ...\n",
    "    nengo.Connection(winput_x.output, learn_node[:N_NEURONS])\n",
    "    nengo.Connection(winput_y.output, learn_node[N_NEURONS:N_NEURONS*2])\n",
    "    nengo.Connection(activity_x.output, learn_node[N_NEURONS*2:N_NEURONS*3])\n",
    "    nengo.Connection(activity_y.output, learn_node[N_NEURONS*3:N_NEURONS*4])\n",
    "    nengo.Connection(std_x.output, learn_node[N_NEURONS*4:N_NEURONS*5])\n",
    "    nengo.Connection(std_y.output, learn_node[N_NEURONS*5:N_NEURONS*6])\n",
    "    #nengo.Connection(xmod_weights.output, learn_node[N_NEURONS*6:])\n",
    "    # ... und wieder zurück\n",
    "    nengo.Connection(learn_node[:N_NEURONS], winput_x.input)\n",
    "    nengo.Connection(learn_node[N_NEURONS:N_NEURONS*2], winput_y.input)\n",
    "    nengo.Connection(learn_node[N_NEURONS*2:N_NEURONS*3], activity_x.input)\n",
    "    nengo.Connection(learn_node[N_NEURONS*3:N_NEURONS*4], activity_y.input)\n",
    "    nengo.Connection(learn_node[N_NEURONS*4:N_NEURONS*5], std_x.input)\n",
    "    nengo.Connection(learn_node[N_NEURONS*5:N_NEURONS*6], std_y.input)\n",
    "    #nengo.Connection(learn_node[N_NEURONS*6:], xmod_weights.input)\n",
    "\n",
    "    #Proben\n",
    "    p_xmod_winput_x = nengo.Probe(winput_x)\n",
    "    p_xmod_winput_y = nengo.Probe(winput_y)\n",
    "    p_xmod_activity_x = nengo.Probe(activity_x)\n",
    "    p_xmod_activity_y = nengo.Probe(activity_y)\n",
    "    p_xmod_std_x = nengo.Probe(std_x)\n",
    "    p_xmod_std_y = nengo.Probe(std_y)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "with nengo.Simulator(net_xmod) as s_xmod:\n",
    "    s_xmod.run_steps(MAX_EPOCHS_XMOD_LEARNING)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisierung activity-Vektoren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.bar(range(N_NEURONS), s_xmod.data[p_xmod_activity_x][-1])\n",
    "plt.title('activity_x')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Wert')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.bar(range(N_NEURONS), s_xmod.data[p_xmod_activity_y][-1])\n",
    "plt.title('activity_y')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Wert')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisierung winput-Vektoren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.bar(range(N_NEURONS), s_xmod.data[p_xmod_winput_x][-1])\n",
    "plt.title('winput_x')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Wert')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.bar(range(N_NEURONS), s_xmod.data[p_xmod_winput_y][-1])\n",
    "plt.title('winput_y')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Wert')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.grid()\n",
    "x = np.linspace(-RADIUS, RADIUS, N_NEURONS)\n",
    "for i in range(N_NEURONS):\n",
    "    # extract the preferred values (wight vector) of each neuron\n",
    "    v_pref = s_xmod.data[p_xmod_winput_x][-1][i]\n",
    "    fx = np.exp(-(x - v_pref)**2 / (2 * s_xmod.data[p_xmod_std_x][-1][i]**2))\n",
    "    plt.plot([x for x in range(N_NEURONS)], fx)\n",
    "    \n",
    "plt.subplot(2, 1, 2)\n",
    "plt.grid()\n",
    "x = np.linspace(-RADIUS, RADIUS, N_NEURONS)\n",
    "for i in range(N_NEURONS):\n",
    "    # extract the preferred values (wight vector) of each neuron\n",
    "    v_pref = s_xmod.data[p_xmod_winput_y][-1][i]\n",
    "    fx = np.exp(-(x - v_pref)**2 / (2 * s_xmod.data[p_xmod_std_y][-1][i]**2))\n",
    "    plt.plot([x for x in range(N_NEURONS)], fx)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisierung std-Vektoren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.bar(range(N_NEURONS), s_xmod.data[p_xmod_std_x][-1])\n",
    "plt.title('std_x')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Wert')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.bar(range(N_NEURONS), s_xmod.data[p_xmod_std_y][-1])\n",
    "plt.title('std_y')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Wert')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisierung xmod-Matrizen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.imshow(XMOD_WEIGHTS[0], cmap='viridis')\n",
    "plt.colorbar() \n",
    "plt.title('XMOD_WEIGHTS x') \n",
    "plt.xlabel('Spaltenindex')\n",
    "plt.ylabel('Zeilenindex')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(XMOD_WEIGHTS[1], cmap='viridis')\n",
    "plt.colorbar() \n",
    "plt.title('XMOD_WEIGHTS y') \n",
    "plt.xlabel('Spaltenindex')\n",
    "plt.ylabel('Zeilenindex')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vollständige Implementierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "source": [
    "reset_matrices()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "source": [
    "class LearnProcess(nengo.Process):\n",
    "    def make_step(self, shape_in, shape_out, dt, rng, state=None):\n",
    "        def step(t, x):\n",
    "            epoch = int(t/DT)\n",
    "\n",
    "            if epoch == 0: #wenn erster Durchlauf, Werte der Neuronen initialisieren\n",
    "                winputs = np.zeros((N_ENS, N_NEURONS))\n",
    "                activities = np.zeros((N_ENS, N_NEURONS))\n",
    "                stds = np.ones((N_ENS, N_NEURONS)) * SIGMA_DEF\n",
    "                #xmod_weights = W_CROSS / W_CROSS.sum()\n",
    "            else:\n",
    "                winputs = np.array([x[:N_NEURONS], x[N_NEURONS:N_NEURONS*2]])\n",
    "                activities = np.array([x[N_NEURONS*2:N_NEURONS*3], x[N_NEURONS*3:N_NEURONS*4]])\n",
    "                stds = np.array([x[N_NEURONS*4:N_NEURONS*5], x[N_NEURONS*5:N_NEURONS*6]])\n",
    "                #xmod_weights = np.array(x[N_NEURONS*6:]).reshape((N_NEURONS, N_NEURONS))\n",
    "            \n",
    "            #Inneres Lernen\n",
    "            if epoch <= MAX_EPOCHS_IN_LEARNING:\n",
    "                (winputs, activities, stds) = inner_learning1(winputs, activities, stds, epoch)\n",
    "\n",
    "            #XMOD-Lernen\n",
    "            activities = \\\n",
    "            covariance_learning1(winputs, activities, stds, epoch)\n",
    "            #oja_learning1(winputs, activities, stds)\n",
    "            #hebbian_learning1(winputs, activities, stds)\n",
    "\n",
    "            return np.concatenate((winputs.flatten(), activities.flatten(), stds.flatten()), axis=None)\n",
    "        return step"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "source": [
    "with nengo.Network() as net:\n",
    "    #Repräsentation der WInput-Vektoren als Ensembles\n",
    "    winput_x = nengo.networks.EnsembleArray(N_NEURONS*50, n_ensembles=N_NEURONS, radius=RADIUS)\n",
    "    winput_y = nengo.networks.EnsembleArray(N_NEURONS*50, n_ensembles=N_NEURONS, radius=RADIUS)\n",
    "\n",
    "    #Repräsentation der Aktivitäts-Vektoren als Ensembles\n",
    "    activity_x = nengo.networks.EnsembleArray(N_NEURONS*50, n_ensembles=N_NEURONS, radius=RADIUS)\n",
    "    activity_y = nengo.networks.EnsembleArray(N_NEURONS*50, n_ensembles=N_NEURONS, radius=RADIUS)\n",
    "\n",
    "    #Repräsentation der std-Vektoren als Ensembles\n",
    "    std_x = nengo.networks.EnsembleArray(N_NEURONS*50, n_ensembles=N_NEURONS, radius=RADIUS)\n",
    "    std_y = nengo.networks.EnsembleArray(N_NEURONS*50, n_ensembles=N_NEURONS, radius=RADIUS)\n",
    "\n",
    "    #xmod_weights = nengo.networks.EnsembleArray(N_NEURONS*N_NEURONS*30, n_ensembles=N_NEURONS*N_NEURONS, radius=RADIUS)\n",
    "\n",
    "    learn_node = nengo.Node(LearnProcess(), size_in=N_NEURONS*N_ENS*3, size_out=N_NEURONS*N_ENS*3)\n",
    "\n",
    "    #Verbindungen von Neuronen der Ensembles zur Lernmethode ...\n",
    "    nengo.Connection(winput_x.output, learn_node[:N_NEURONS])\n",
    "    nengo.Connection(winput_y.output, learn_node[N_NEURONS:N_NEURONS*2])\n",
    "    nengo.Connection(activity_x.output, learn_node[N_NEURONS*2:N_NEURONS*3])\n",
    "    nengo.Connection(activity_y.output, learn_node[N_NEURONS*3:N_NEURONS*4])\n",
    "    nengo.Connection(std_x.output, learn_node[N_NEURONS*4:N_NEURONS*5])\n",
    "    nengo.Connection(std_y.output, learn_node[N_NEURONS*5:N_NEURONS*6])\n",
    "    #nengo.Connection(xmod_weights.output, learn_node[N_NEURONS*6:])\n",
    "    # ... und wieder zurück\n",
    "    nengo.Connection(learn_node[:N_NEURONS], winput_x.input)\n",
    "    nengo.Connection(learn_node[N_NEURONS:N_NEURONS*2], winput_y.input)\n",
    "    nengo.Connection(learn_node[N_NEURONS*2:N_NEURONS*3], activity_x.input)\n",
    "    nengo.Connection(learn_node[N_NEURONS*3:N_NEURONS*4], activity_y.input)\n",
    "    nengo.Connection(learn_node[N_NEURONS*4:N_NEURONS*5], std_x.input)\n",
    "    nengo.Connection(learn_node[N_NEURONS*5:N_NEURONS*6], std_y.input)\n",
    "    #nengo.Connection(learn_node[N_NEURONS*6:], xmod_weights.input)\n",
    "\n",
    "\n",
    "    #Proben\n",
    "    p_winput_x = nengo.Probe(winput_x.output)\n",
    "    p_winput_y = nengo.Probe(winput_y.output)\n",
    "    p_activity_x = nengo.Probe(activity_x.output)\n",
    "    p_activity_y = nengo.Probe(activity_y.output)\n",
    "    p_std_x = nengo.Probe(std_x.output)\n",
    "    p_std_y = nengo.Probe(std_y.output)\n",
    "    #p_xmod_weights = nengo.Probe(xmod_weights.output)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "source": [
    "with nengo.Simulator(net, dt=DT) as s:\n",
    "    s.run_steps(MAX_EPOCHS_XMOD_LEARNING)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisierung activity-Vektoren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.bar(range(N_NEURONS), s.data[p_activity_x][-1])\n",
    "plt.title('activity_x')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Wert')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.bar(range(N_NEURONS), s.data[p_activity_y][-1])\n",
    "plt.title('activity_y')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Wert')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisierung winput-Vektoren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.bar(range(N_NEURONS), s.data[p_winput_x][-1])\n",
    "plt.title('winput_x')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Wert')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.bar(range(N_NEURONS), s.data[p_winput_y][-1])\n",
    "plt.title('winput_y')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Wert')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.grid()\n",
    "x = np.linspace(-RADIUS, RADIUS, N_NEURONS)\n",
    "for i in range(N_NEURONS):\n",
    "    # extract the preferred values (wight vector) of each neuron\n",
    "    v_pref = s.data[p_winput_x][i]\n",
    "    fx = np.exp(-(x - v_pref)**2 / (2 * s.data[p_std_x][i]**2))\n",
    "    plt.plot([x for x in range(N_NEURONS)], fx)\n",
    "    \n",
    "plt.subplot(2, 1, 2)\n",
    "plt.grid()\n",
    "x = np.linspace(-RADIUS, RADIUS, N_NEURONS)\n",
    "for i in range(N_NEURONS):\n",
    "    # extract the preferred values (wight vector) of each neuron\n",
    "    v_pref = s.data[p_winput_y][i]\n",
    "    fx = np.exp(-(x - v_pref)**2 / (2 * s.data[p_std_y][i]**2))\n",
    "    plt.plot([x for x in range(N_NEURONS)], fx)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisierung std-Vektoren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.bar(range(N_NEURONS), s.data[p_std_x][-1])\n",
    "plt.title('std_x')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Wert')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.bar(range(N_NEURONS), s.data[p_std_y][-1])\n",
    "plt.title('std_y')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Wert')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisierung xmod-Matrizen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.imshow(XMOD_WEIGHTS[0], cmap='viridis')\n",
    "plt.colorbar() \n",
    "plt.title('XMOD_WEIGHTS x') \n",
    "plt.xlabel('Spaltenindex')\n",
    "plt.ylabel('Zeilenindex')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(XMOD_WEIGHTS[1], cmap='viridis')\n",
    "plt.colorbar() \n",
    "plt.title('XMOD_WEIGHTS y') \n",
    "plt.xlabel('Spaltenindex')\n",
    "plt.ylabel('Zeilenindex')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ansatz 2: Nengo-Implementierung nur des Aktivitäts-Vektor als Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nur Inner-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "reset_matrices()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "with nengo.Network() as model_inner:\n",
    "    #Ensembles auf denen das innere Lernen durchgeführt wird\n",
    "    #Repräsentieren dabei den Aktivitätsvektor eines SOM\n",
    "    x_inner = nengo.networks.EnsembleArray(N_NEURONS*30, n_ensembles=N_NEURONS, radius=RADIUS)\n",
    "    y_inner = nengo.networks.EnsembleArray(N_NEURONS*30, n_ensembles=N_NEURONS, radius=RADIUS)\n",
    "\n",
    "    #Methode, welche inners Lernen durchführt\n",
    "    def inner_learn(t, x):\n",
    "        # Berechnen der aktuellen Epoche (vergangene Zeit / Schrittweite)\n",
    "        epoch = int(t/DT)\n",
    "\n",
    "        if epoch == 1: #wenn erster Durchlauf, Werte der Neuronen initialisieren\n",
    "            activities = np.zeros((N_ENS, N_NEURONS))\n",
    "        else:\n",
    "            activities = np.array([x[:N_NEURONS], x[N_NEURONS:]])\n",
    "\n",
    "        #Inneres Lernen\n",
    "        if epoch <= MAX_EPOCHS_IN_LEARNING:\n",
    "            activities = inner_learning(activities, epoch)\n",
    "        \n",
    "        return activities.flatten()\n",
    "\n",
    "    inner_learn_node = nengo.Node(inner_learn, size_in=N_NEURONS*N_ENS, size_out=N_NEURONS*N_ENS)\n",
    "\n",
    "    #Verbindungen von Neuronen der Ensembles zu inneren Lernmethode ...\n",
    "    nengo.Connection(x_inner.output, inner_learn_node[:N_NEURONS])\n",
    "    nengo.Connection(y_inner.output, inner_learn_node[N_NEURONS:])\n",
    "    # ... und wieder zurück\n",
    "    nengo.Connection(inner_learn_node[:N_NEURONS], x_inner.input)\n",
    "    nengo.Connection(inner_learn_node[N_NEURONS:], y_inner.input)\n",
    "\n",
    "    #Sammeln der Proben\n",
    "    x_inner_probe = nengo.Probe(x_inner)\n",
    "    y_inner_probe = nengo.Probe(y_inner)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "with nengo.Simulator(model_inner, dt=DT) as sim_inner:\n",
    "    sim_inner.run_steps(MAX_EPOCHS_IN_LEARNING)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisierung Aktivitätsvektoren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.bar(range(N_NEURONS), sim_inner.data[x_inner_probe][-1])\n",
    "plt.title('activity_x')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Wert')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.bar(range(N_NEURONS), sim_inner.data[y_inner_probe][-1])\n",
    "plt.title('activity_y')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Wert')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisierung winput-Vektoren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.bar(range(N_NEURONS), INPUT_WEIGHTS[0])\n",
    "plt.title('winput_x')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Wert')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.bar(range(N_NEURONS), INPUT_WEIGHTS[1])\n",
    "plt.title('winput_y')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Wert')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.hist(INPUT_WEIGHTS[0],bins=50,facecolor=\"blue\", edgecolor=\"black\", alpha=0.7)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.hist(INPUT_WEIGHTS[1],bins=50,facecolor=\"blue\", edgecolor=\"black\", alpha=0.7)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisierung std-Vektoren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.bar(range(N_NEURONS), STD[0])\n",
    "plt.title('std_x')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Wert')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.bar(range(N_NEURONS), STD[1])\n",
    "plt.title('std_y')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Wert')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisierung Tuning-Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "pref = [1, 6, 13, 40, 45, 85, 90, 98]\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "v_pref = np.sort(INPUT_WEIGHTS[0],axis=0)\n",
    "for idx in range(len(pref)):\n",
    "    # extract the preferred values (wight vector) of each neuron\n",
    "    idx_pref = pref[idx]\n",
    "    fx = np.exp(-(x - v_pref[idx_pref])**2/(2*STD[0][idx_pref]**2))\n",
    "    plt.plot([x for x in range(N_NEURONS)],fx)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "v_pref = np.sort(INPUT_WEIGHTS[1],axis=0)\n",
    "for idx in range(len(pref)):\n",
    "    # extract the preferred values (wight vector) of each neuron\n",
    "    idx_pref = pref[idx]\n",
    "    fx = np.exp(-(x - v_pref[idx_pref])**2/(2*STD[1][idx_pref]**2))\n",
    "    plt.plot([x for x in range(N_NEURONS)],fx)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.grid()\n",
    "x = np.linspace(-RADIUS, RADIUS, N_NEURONS)\n",
    "for i in range(N_NEURONS):\n",
    "    # extract the preferred values (wight vector) of each neuron\n",
    "    v_pref = INPUT_WEIGHTS[0][i]\n",
    "    fx = np.exp(-(x - v_pref)**2 / (2 * STD[0][i]**2))\n",
    "    plt.plot([x for x in range(N_NEURONS)], fx)\n",
    "    \n",
    "plt.subplot(2, 1, 2)\n",
    "plt.grid()\n",
    "x = np.linspace(-RADIUS, RADIUS, N_NEURONS)\n",
    "for i in range(N_NEURONS):\n",
    "    # extract the preferred values (wight vector) of each neuron\n",
    "    v_pref = INPUT_WEIGHTS[1][i]\n",
    "    fx = np.exp(-(x - v_pref)**2 / (2 * STD[1][i]**2))\n",
    "    plt.plot([x for x in range(N_NEURONS)], fx)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisierung der xmod-Matrizen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.imshow(XMOD_WEIGHTS[0], cmap='viridis')\n",
    "plt.colorbar() \n",
    "plt.title('XMOD_WEIGHTS x') \n",
    "plt.xlabel('Spaltenindex')\n",
    "plt.ylabel('Zeilenindex')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(XMOD_WEIGHTS[1], cmap='viridis')\n",
    "plt.colorbar() \n",
    "plt.title('XMOD_WEIGHTS y') \n",
    "plt.xlabel('Spaltenindex')\n",
    "plt.ylabel('Zeilenindex')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nur XMod-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "with nengo.Network() as model_xmod:\n",
    "    #Ensembles auf denen das innere Lernen durchgeführt wird\n",
    "    #Repräsentieren dabei den Aktivitätsvektor eines SOM\n",
    "    x_xmod = nengo.networks.EnsembleArray(N_NEURONS*30, n_ensembles=N_NEURONS, radius=RADIUS)\n",
    "    y_xmod = nengo.networks.EnsembleArray(N_NEURONS*30, n_ensembles=N_NEURONS, radius=RADIUS)\n",
    "\n",
    "    #Methode, welche XMOD-Lernen durchführt\n",
    "    def xmod_learn(t,x):\n",
    "        activities = np.array([x[:N_NEURONS], x[N_NEURONS:]])\n",
    "\n",
    "        #XMOD-Lernen\n",
    "        activities =\\\n",
    "        covariance_learning(activities, int(t/DT))\n",
    "        #oja_learning(activities)\n",
    "        #hebbian_learning(activities)\n",
    "\n",
    "        return activities.flatten()\n",
    "\n",
    "    xmod_learn_node = nengo.Node(xmod_learn, size_in=N_NEURONS*N_ENS, size_out=N_NEURONS*N_ENS)\n",
    "\n",
    "    #Verbindungen von Neuronen der Ensembles zu xmod Lernmethode ...\n",
    "    nengo.Connection(x_xmod.output, xmod_learn_node[:N_NEURONS])\n",
    "    nengo.Connection(y_xmod.output, xmod_learn_node[N_NEURONS:])\n",
    "    # ... und wieder zurück\n",
    "    nengo.Connection(xmod_learn_node[:N_NEURONS], x_xmod.input)\n",
    "    nengo.Connection(xmod_learn_node[N_NEURONS:], y_xmod.input)\n",
    "\n",
    "    #Sammeln der Proben\n",
    "    x_xmod_probe = nengo.Probe(x_xmod)\n",
    "    y_xmod_probe = nengo.Probe(y_xmod)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "with nengo.Simulator(model_xmod, dt=DT) as sim_xmod:\n",
    "    sim_xmod.run_steps(MAX_EPOCHS_XMOD_LEARNING)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisierung Aktivitätsvektoren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.bar(range(N_NEURONS), sim_xmod.data[x_xmod_probe][-1])\n",
    "plt.title('activity_x')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Wert')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.bar(range(N_NEURONS), sim_xmod.data[y_xmod_probe][-1])\n",
    "plt.title('activity_y')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Wert')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisierung winput-Vektoren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.bar(range(N_NEURONS), INPUT_WEIGHTS[0])\n",
    "plt.title('winput_x')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Wert')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.bar(range(N_NEURONS), INPUT_WEIGHTS[1])\n",
    "plt.title('winput_y')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Wert')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.hist(INPUT_WEIGHTS[0],bins=50,facecolor=\"blue\", edgecolor=\"black\", alpha=0.7)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.hist(INPUT_WEIGHTS[1],bins=50,facecolor=\"blue\", edgecolor=\"black\", alpha=0.7)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisierung std-Vektoren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.bar(range(N_NEURONS), STD[0])\n",
    "plt.title('std_x')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Wert')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.bar(range(N_NEURONS), STD[1])\n",
    "plt.title('std_y')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Wert')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisierung Tuning-Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "pref = [1, 6, 13, 40, 45, 85, 90, 98]\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "v_pref = np.sort(INPUT_WEIGHTS[0],axis=0)\n",
    "for idx in range(len(pref)):\n",
    "    # extract the preferred values (wight vector) of each neuron\n",
    "    idx_pref = pref[idx]\n",
    "    fx = np.exp(-(x - v_pref[idx_pref])**2/(2*STD[0][idx_pref]**2))\n",
    "    plt.plot([x for x in range(N_NEURONS)],fx)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "v_pref = np.sort(INPUT_WEIGHTS[1],axis=0)\n",
    "for idx in range(len(pref)):\n",
    "    # extract the preferred values (wight vector) of each neuron\n",
    "    idx_pref = pref[idx]\n",
    "    fx = np.exp(-(x - v_pref[idx_pref])**2/(2*STD[1][idx_pref]**2))\n",
    "    plt.plot([x for x in range(N_NEURONS)],fx)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.grid()\n",
    "x = np.linspace(-RADIUS, RADIUS, N_NEURONS)\n",
    "for i in range(N_NEURONS):\n",
    "    # extract the preferred values (wight vector) of each neuron\n",
    "    v_pref = INPUT_WEIGHTS[0][i]\n",
    "    fx = np.exp(-(x - v_pref)**2 / (2 * STD[0][i]**2))\n",
    "    plt.plot([x for x in range(N_NEURONS)], fx)\n",
    "    \n",
    "plt.subplot(2, 1, 2)\n",
    "plt.grid()\n",
    "x = np.linspace(-RADIUS, RADIUS, N_NEURONS)\n",
    "for i in range(N_NEURONS):\n",
    "    # extract the preferred values (wight vector) of each neuron\n",
    "    v_pref = INPUT_WEIGHTS[1][i]\n",
    "    fx = np.exp(-(x - v_pref)**2 / (2 * STD[1][i]**2))\n",
    "    plt.plot([x for x in range(N_NEURONS)], fx)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisierung xmod_weights-Matrizen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.imshow(XMOD_WEIGHTS[0], cmap='viridis')\n",
    "plt.colorbar() \n",
    "plt.title('XMOD_WEIGHTS x') \n",
    "plt.xlabel('Spaltenindex')\n",
    "plt.ylabel('Zeilenindex')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(XMOD_WEIGHTS[1], cmap='viridis')\n",
    "plt.colorbar() \n",
    "plt.title('XMOD_WEIGHTS y') \n",
    "plt.xlabel('Spaltenindex')\n",
    "plt.ylabel('Zeilenindex')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vollständige Implementierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "source": [
    "reset_matrices()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "source": [
    "with nengo.Network() as model:\n",
    "    #Ensembles auf denen das innere Lernen durchgeführt wird\n",
    "    #Repräsentieren dabei den Aktivitätsvektor eines SOM\n",
    "    x = nengo.networks.EnsembleArray(N_NEURONS*30, n_ensembles=N_NEURONS, radius=RADIUS)\n",
    "    y = nengo.networks.EnsembleArray(N_NEURONS*30, n_ensembles=N_NEURONS, radius=RADIUS)\n",
    "\n",
    "    #Methode, welche inners Lernen durchführt\n",
    "    def inner_learn(t, x):\n",
    "        # Berechnen der aktuellen Epoche (vergangene Zeit / Schrittweite)\n",
    "        epoch = int(t/DT)\n",
    "\n",
    "        if epoch == 1: #wenn erster Durchlauf, Werte der Neuronen initialisieren\n",
    "            activities = np.zeros((N_ENS, N_NEURONS))\n",
    "        else:\n",
    "            activities = np.array([x[:N_NEURONS], x[N_NEURONS:]])\n",
    "\n",
    "        #Inneres Lernen\n",
    "        if epoch <= MAX_EPOCHS_IN_LEARNING:\n",
    "            activities = inner_learning(activities, epoch)\n",
    "        \n",
    "        return activities.flatten()\n",
    "\n",
    "    #Methode, welche XMOD-Lernen durchführt\n",
    "    def xmod_learn(t,x):\n",
    "        activities = np.array([x[:N_NEURONS], x[N_NEURONS:]])\n",
    "\n",
    "        #XMOD-Lernen\n",
    "        activities =\\\n",
    "        covariance_learning(activities, int(t/DT))\n",
    "        #oja_learning(activities)\n",
    "        #hebbian_learning(activities)\n",
    "\n",
    "        return activities.flatten()\n",
    "\n",
    "    inner_learn_node = nengo.Node(inner_learn, size_in=N_NEURONS*N_ENS, size_out=N_NEURONS*N_ENS)\n",
    "    xmod_learn_node = nengo.Node(xmod_learn, size_in=N_NEURONS*N_ENS, size_out=N_NEURONS*N_ENS)\n",
    "\n",
    "    #Verbindungen von Neuronen der Ensembles zu inneren Lernmethode ...\n",
    "    nengo.Connection(x.output, inner_learn_node[:N_NEURONS])\n",
    "    nengo.Connection(y.output, inner_learn_node[N_NEURONS:])\n",
    "    # ... dann zur XMod-Lernmethode ...\n",
    "    nengo.Connection(inner_learn_node, xmod_learn_node)\n",
    "    # ... und wieder zurück\n",
    "    nengo.Connection(xmod_learn_node[:N_NEURONS], x.input)\n",
    "    nengo.Connection(xmod_learn_node[N_NEURONS:], y.input)\n",
    "\n",
    "    #Sammeln der Proben\n",
    "    x_probe = nengo.Probe(x.output)\n",
    "    y_probe = nengo.Probe(y.output)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "source": [
    "with nengo.Simulator(model, dt=DT) as sim:\n",
    "    sim.run_steps(MAX_EPOCHS_XMOD_LEARNING)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisierung Aktivitätsvektoren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.bar(range(N_NEURONS), sim.data[x_probe][-1])\n",
    "plt.title('activity_x')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Wert')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.bar(range(N_NEURONS), sim.data[y_probe][-1])\n",
    "plt.title('activity_y')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Wert')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisierung winput-Vektoren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.bar(range(N_NEURONS), INPUT_WEIGHTS[0])\n",
    "plt.title('winput_x')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Wert')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.bar(range(N_NEURONS), INPUT_WEIGHTS[1])\n",
    "plt.title('winput_y')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Wert')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.hist(INPUT_WEIGHTS[0],bins=50,facecolor=\"blue\", edgecolor=\"black\", alpha=0.7)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.hist(INPUT_WEIGHTS[1],bins=50,facecolor=\"blue\", edgecolor=\"black\", alpha=0.7)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisierung std-Vektoren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.bar(range(N_NEURONS), STD[0])\n",
    "plt.title('std_x')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Wert')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.bar(range(N_NEURONS), STD[1])\n",
    "plt.title('std_y')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Wert')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisierung Tuning-Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.grid()\n",
    "x = np.linspace(-RADIUS, RADIUS, N_NEURONS)\n",
    "for i in range(N_NEURONS):\n",
    "    # extract the preferred values (wight vector) of each neuron\n",
    "    v_pref = INPUT_WEIGHTS[0][i]\n",
    "    fx = np.exp(-(x - v_pref)**2 / (2 * STD[0][i]**2))\n",
    "    plt.plot([x for x in range(N_NEURONS)], fx)\n",
    "    \n",
    "plt.subplot(2, 1, 2)\n",
    "plt.grid()\n",
    "x = np.linspace(-RADIUS, RADIUS, N_NEURONS)\n",
    "for i in range(N_NEURONS):\n",
    "    # extract the preferred values (wight vector) of each neuron\n",
    "    v_pref = INPUT_WEIGHTS[1][i]\n",
    "    fx = np.exp(-(x - v_pref)**2 / (2 * STD[1][i]**2))\n",
    "    plt.plot([x for x in range(N_NEURONS)], fx)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "source": [
    "pref = [1, 6, 13, 40, 45, 85, 90, 98]\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "v_pref = np.sort(INPUT_WEIGHTS[0],axis=0)\n",
    "for i in range(len(pref)):\n",
    "    # extract the preferred values (wight vector) of each neuron\n",
    "    i_pref = pref[i]\n",
    "    fx = np.exp(-(x - v_pref[i_pref])**2 / (2 * STD[0][i_pref]**2))\n",
    "    plt.plot([x for x in range(N_NEURONS)],fx)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "v_pref = np.sort(INPUT_WEIGHTS[1],axis=0)\n",
    "for idx in range(len(pref)):\n",
    "    # extract the preferred values (wight vector) of each neuron\n",
    "    idx_pref = pref[idx]\n",
    "    fx = np.exp(-(x - v_pref[i_pref])**2 / (2 * STD[1][i_pref]**2))\n",
    "    plt.plot([x for x in range(N_NEURONS)],fx)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisierung xmod-Matrizen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.imshow(XMOD_WEIGHTS[0], cmap='viridis')\n",
    "plt.colorbar() \n",
    "plt.title('XMOD_WEIGHTS x') \n",
    "plt.xlabel('Spaltenindex')\n",
    "plt.ylabel('Zeilenindex')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(XMOD_WEIGHTS[1], cmap='viridis')\n",
    "plt.colorbar() \n",
    "plt.title('XMOD_WEIGHTS y') \n",
    "plt.xlabel('Spaltenindex')\n",
    "plt.ylabel('Zeilenindex')"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
